{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f3ccba7",
   "metadata": {},
   "source": [
    "# CatBoost json tutorial\n",
    "\n",
    "This notebook focuses on binary classification, but it can be used as a basis to extend these concepts to other uses of CatBoost.\n",
    "\n",
    "Other resources:\n",
    "1. [CatBoost JSON model tutorial](https://github.com/catboost/tutorials/blob/master/model_analysis/model_export_as_json_tutorial.ipynb) - on `catboost` repo\n",
    "2. [Explanation of Json model format of CatBoost](https://parasmalik.blogspot.com/2020/07/explanation-of-json-model-format-of.html) - blogpost by Paras Malik\n",
    "3. [CatBoost documentation](https://catboost.ai/docs/en/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c7ce3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from clickhouse_cityhash.cityhash import CityHash64\n",
    "from scipy.special import expit\n",
    "from tqdm import tqdm\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f36971b",
   "metadata": {},
   "source": [
    "## Load and process dataset\n",
    "\n",
    "As an example we will use [Adult \"Census Income\" dataset](https://archive.ics.uci.edu/dataset/2/adult) as it has many categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4041c827",
   "metadata": {},
   "outputs": [],
   "source": [
    "adult = fetch_ucirepo(id=2)\n",
    "X = adult.data.features\n",
    "y = adult.data.targets\n",
    "\n",
    "y_unique = y[\"income\"].unique()\n",
    "mapping = {value: 1 if \">\" in value else 0 for value in y_unique} # label needs cleaning, 1 == income > 50k, 0 == income < 50k\n",
    "y = y[\"income\"].map(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c82c8b",
   "metadata": {},
   "source": [
    "CatBoost does not handle missing values in categorical features. We need to fill them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c802b66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = X.select_dtypes(include=\"object\").columns.to_list()\n",
    "X.loc[:, cat_features] = X[cat_features].fillna(\"missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f92250",
   "metadata": {},
   "source": [
    "In order to see how CatBoost handles missing values in numerical features we need to artifically insert them since numerical features in \"Census Income\" dataset are filled completely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4027955",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.loc[:,\"capital-gain\"] = X[\"capital-gain\"].astype(np.float64)\n",
    "to_nans = X[\"capital-gain\"].sample(frac=0.02).index\n",
    "X.loc[to_nans, \"capital-gain\"] = None\n",
    "X.loc[:,\"capital-loss\"] = X[\"capital-loss\"].astype(np.float64)\n",
    "to_nans = X[\"capital-loss\"].sample(frac=0.02).index\n",
    "X.loc[to_nans, \"capital-loss\"] =None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e512561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   age             48842 non-null  int64  \n",
      " 1   workclass       48842 non-null  object \n",
      " 2   fnlwgt          48842 non-null  int64  \n",
      " 3   education       48842 non-null  object \n",
      " 4   education-num   48842 non-null  int64  \n",
      " 5   marital-status  48842 non-null  object \n",
      " 6   occupation      48842 non-null  object \n",
      " 7   relationship    48842 non-null  object \n",
      " 8   race            48842 non-null  object \n",
      " 9   sex             48842 non-null  object \n",
      " 10  capital-gain    47865 non-null  float64\n",
      " 11  capital-loss    47865 non-null  float64\n",
      " 12  hours-per-week  48842 non-null  int64  \n",
      " 13  native-country  48842 non-null  object \n",
      "dtypes: float64(2), int64(4), object(8)\n",
      "memory usage: 5.2+ MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fcffc0",
   "metadata": {},
   "source": [
    "## Train model\n",
    "\n",
    "We need to specify which features are categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc69fd29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7b74e4fb5be0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CatBoostClassifier(cat_features=cat_features, random_state=42, allow_writing_files=False, verbose=False)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df73f8a",
   "metadata": {},
   "source": [
    "## Export model to json\n",
    "\n",
    "We can export model to different formats. Json is human readable. If we also pass training dataset in `pool` parameter, hash values of the categories will be saved (more on that later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b6daf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pool = Pool(X, cat_features=cat_features)\n",
    "model.save_model(\"catboost_model.json\", format=\"json\", pool=X_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544b7383",
   "metadata": {},
   "source": [
    "## Explore CatBoost json\n",
    "\n",
    "Let's load back json file to a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "154cc344",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"catboost_model.json\", mode=\"r\") as f:\n",
    "    model_json = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31608978",
   "metadata": {},
   "source": [
    "`model_json` contains 4 keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f248d945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ctr_data\n",
      "features_info\n",
      "model_info\n",
      "oblivious_trees\n",
      "scale_and_bias\n"
     ]
    }
   ],
   "source": [
    "print(*model_json.keys(), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e40322",
   "metadata": {},
   "source": [
    "Brief description:\n",
    "- `ctr_data` - data used to calculate CTRs (more on that later)\n",
    "- `feature_info` - feature names, types, borders used for splits (more on that later)\n",
    "- `model_info` - hyperparameters and other informations\n",
    "- `oblivious_trees` - splits, leaf values and leaf weights of all trees\n",
    "- `scale_and_bias` - final modification of prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72764843",
   "metadata": {},
   "source": [
    "### Numerical features\n",
    "\n",
    "Information about numerical features are kept in `model_json[\"feature_info\"][\"float_features\"]` which is a list of one dictionary per numerical feature. Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e03e68ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'borders': [18.5,\n",
      "             23.5,\n",
      "             24.5,\n",
      "             25.5,\n",
      "             26.5,\n",
      "             27.5,\n",
      "             28.5,\n",
      "             29.5,\n",
      "             30.5,\n",
      "             31.5,\n",
      "             32.5,\n",
      "             33.5,\n",
      "             34.5,\n",
      "             35.5,\n",
      "             36.5,\n",
      "             37.5,\n",
      "             38.5,\n",
      "             39.5,\n",
      "             40.5,\n",
      "             41.5,\n",
      "             42.5,\n",
      "             43.5,\n",
      "             44.5,\n",
      "             45.5,\n",
      "             46.5,\n",
      "             47.5,\n",
      "             48.5,\n",
      "             49.5,\n",
      "             50.5,\n",
      "             51.5,\n",
      "             52.5,\n",
      "             53.5,\n",
      "             54.5,\n",
      "             55.5,\n",
      "             56.5,\n",
      "             57.5,\n",
      "             58.5,\n",
      "             59.5,\n",
      "             60.5,\n",
      "             61.5,\n",
      "             63.5,\n",
      "             64.5,\n",
      "             65.5,\n",
      "             66.5,\n",
      "             68.5,\n",
      "             69.5,\n",
      "             70.5,\n",
      "             71.5,\n",
      "             72.5,\n",
      "             73.5,\n",
      "             76.5,\n",
      "             77.5,\n",
      "             79.5,\n",
      "             81.5,\n",
      "             82.5,\n",
      "             83.5,\n",
      "             85.5],\n",
      " 'feature_id': 'age',\n",
      " 'feature_index': 0,\n",
      " 'feature_name': 'age',\n",
      " 'flat_feature_index': 0,\n",
      " 'has_nans': False,\n",
      " 'nan_value_treatment': 'AsIs'}\n"
     ]
    }
   ],
   "source": [
    "pprint(model_json[\"features_info\"][\"float_features\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24dbb32",
   "metadata": {},
   "source": [
    "- `borders` - values of all borders in splits which used this feature (if there are `n_b` borders it means that model divided this feature into `n_b+1` bins)\n",
    "- `feature_id`, `feature_name` - feature name\n",
    "- `feature_index` - feature index BUT among float features\n",
    "- `flat_feature_index` - feature index BUT among all features\n",
    "- `has_nans` - if missing values were seen during training\n",
    "- `nan_value_treatment` - how to handle missing values\n",
    "\n",
    "#### Missing values\n",
    "CatBoost has different strategies for handling missing values in numerical features based on parameter `nan_mode`, which is kept in\n",
    "```python\n",
    "model_json[\"model_info\"][\"params\"][\"data_processing_options\"][\"float_features_binarization\"][\"nan_mode\"]\n",
    "```\n",
    "By default `nan_mode=\"Min\"` - it encodes them as smaller than any value. From practical point of view we can recreate this behaviour creating a function replaces missing values with e.g. `min(borders)-1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "993a8475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_nans(X: pd.DataFrame, model_json: dict) -> pd.DataFrame:\n",
    "    X = X.copy(deep=True)\n",
    "    nan_mode = model_json[\"model_info\"][\"params\"][\"data_processing_options\"][\n",
    "        \"float_features_binarization\"\n",
    "    ][\"nan_mode\"]\n",
    "    float_features = model_json[\"features_info\"].get(\"float_features\", [])\n",
    "    for feature_dict in float_features:\n",
    "        feature = feature_dict[\"feature_id\"]\n",
    "        if nan_mode == \"Forbidden\":\n",
    "            if X.loc[:, feature].isna().sum() != 0:\n",
    "                raise ValueError(\"NAs are not allowed!\")\n",
    "        elif nan_mode == \"Max\":\n",
    "            replace_value = max(feature_dict[\"borders\"]) + 1\n",
    "            X.loc[:, feature] = X[feature].fillna(replace_value)\n",
    "        else:\n",
    "            replace_value = min(feature_dict[\"borders\"]) - 1\n",
    "        X.loc[:, feature] = X[feature].fillna(replace_value)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f0b5f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   age             48842 non-null  int64  \n",
      " 1   workclass       48842 non-null  object \n",
      " 2   fnlwgt          48842 non-null  int64  \n",
      " 3   education       48842 non-null  object \n",
      " 4   education-num   48842 non-null  int64  \n",
      " 5   marital-status  48842 non-null  object \n",
      " 6   occupation      48842 non-null  object \n",
      " 7   relationship    48842 non-null  object \n",
      " 8   race            48842 non-null  object \n",
      " 9   sex             48842 non-null  object \n",
      " 10  capital-gain    48842 non-null  float64\n",
      " 11  capital-loss    48842 non-null  float64\n",
      " 12  hours-per-week  48842 non-null  int64  \n",
      " 13  native-country  48842 non-null  object \n",
      "dtypes: float64(2), int64(4), object(8)\n",
      "memory usage: 5.2+ MB\n"
     ]
    }
   ],
   "source": [
    "X_cb = preprocessing_nans(X, model_json=model_json)\n",
    "X_cb.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f10e915",
   "metadata": {},
   "source": [
    "### Categorical features\n",
    "\n",
    "CatBoost uses CTR (click-through rate) or one-hot encoding for categorical features (depending on the parameter `one_hot_max_size`). It can combine categorical feature with other categorical features or numerical splits to create *feature combination*. Simlar data to numerical features are in\n",
    "```python\n",
    "model_json[\"features_info\"][\"categorical_features\"]\n",
    "```\n",
    "However, there is no information about `borders`. Instead, if given feature was one-hot encoded, special hash (more on that later) is stored in key `values`.\n",
    "Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8717384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature_id': 'sex',\n",
      " 'feature_index': 6,\n",
      " 'feature_name': 'sex',\n",
      " 'flat_feature_index': 9,\n",
      " 'values': [-2114564283]}\n"
     ]
    }
   ],
   "source": [
    "pprint(model_json[\"features_info\"][\"categorical_features\"][6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d659f29b",
   "metadata": {},
   "source": [
    "#### Missing values\n",
    "CatBoost does not allow missing values in categorical features. As you've seen there is no `nan_value_treatment` key.\n",
    "\n",
    "#### CTR\n",
    "CTRs can be thought of as new numerical features. Information about them are stored in:\n",
    "```python\n",
    "model_json[\"features_info\"][\"ctrs\"]\n",
    "```\n",
    "and in\n",
    "```python\n",
    "model_json[\"ctr_data\"]\n",
    "```\n",
    "\n",
    "For simplification we will describe CTRs for binary classification.\n",
    " \n",
    "There are several different types of CTRs considered by CatBoost. Two main ones are:\n",
    "1. Borders\n",
    "$$\n",
    "ctr = \\frac{numberOfSuccessInCategory + prior_{numerator}}{numberOfSuccessInCategory + numberOfFailuresInCategory + prior_{denominator}}\n",
    "$$\n",
    "- It is basically [TargetEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.TargetEncoder.html) with prior\n",
    "- It encodes features as mean of the target conditioned on category\n",
    "- It encodes *quality* of the category - how good it is\n",
    "2. Counter\n",
    "$$\n",
    "ctr = \\frac{numberOfInstancesInCategory + prior_{numerator}}{numberOfInstancesInLargestCategory + prior_{denominator}}\n",
    "$$\n",
    "- It encodes frequency of the feature - how often it appeared in the training data\n",
    "\n",
    "Some information how CatBoost uses CTRs\n",
    "- During training each tree sees different permutation of instances and calculates CTRs *online* - meaning the value for each instance depends on values of instances before it in given permutation.\n",
    "- During inference the values of CTRs are fixed.\n",
    "- For regression target values are quantized and turned in to multiclass classification - for each class CTRs are calculated separately\n",
    "\n",
    "##### Feature combination\n",
    "CatBoost also considers *feature combinations* - it creates new categorical feature by combining few categorical features e.g. `feature_1 = \"red\"` and `feature_2=\"square\"` $\\Rightarrow$ `feature_3=\"red|square\"` (well, not exactly - we will see how exactly it is done later).\n",
    "\n",
    "Combination can also be done with numerical splits which can be interpreted binary categorical variable e.g. `feature_4 > 3.5` $\\Rightarrow$ `0` or `1`, which later is combined with categorical feature e.g. `feature_5=\"red|1\"` (again - we will see how it is done exactly later).\n",
    "\n",
    "##### Expand model json\n",
    "CatBoost stores all necessary information in the `json` export. However, some of them are in *raw* form. So if we want to analyze model we can expand it and make our life easier.\n",
    "\n",
    "First, we can add names of the *effective* CTR features. Information about elements are stored in\n",
    "```python\n",
    "model_json[\"features_info\"][\"ctrs\"][ctr_idx][\"elements\"]\n",
    "```\n",
    "while CTR type (`Borders` or `Counter`) and $prior_{numerator}$ are in `ctr_type` and `prior_numerator` key, respectively.\n",
    "Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdb8f192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'borders': [4.999999046325684],\n",
      " 'ctr_type': 'Borders',\n",
      " 'elements': [{'cat_feature_index': 1,\n",
      "               'combination_element': 'cat_feature_value'},\n",
      "              {'border': 40.5,\n",
      "               'combination_element': 'float_feature',\n",
      "               'float_feature_index': 5},\n",
      "              {'border': 45.5,\n",
      "               'combination_element': 'float_feature',\n",
      "               'float_feature_index': 0}],\n",
      " 'identifier': '{\"identifier\":[{\"cat_feature_index\":1,\"combination_element\":\"cat_feature_value\"},{\"border\":40.5,\"combination_element\":\"float_feature\",\"float_feature_index\":5},{\"border\":45.5,\"combination_element\":\"float_feature\",\"float_feature_index\":0}],\"type\":\"Borders\"}',\n",
      " 'prior_denomerator': 1,\n",
      " 'prior_numerator': 0,\n",
      " 'scale': 15,\n",
      " 'shift': 0,\n",
      " 'target_border_idx': 0}\n"
     ]
    }
   ],
   "source": [
    "pprint(model_json[\"features_info\"][\"ctrs\"][200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0f772b",
   "metadata": {},
   "source": [
    "Here is function that adds `feature_id` to CTRs. This `feature_id` is constructed in such a way that encodes all necessary information to identify given CTR e.g. `workclass|race|age>24:Borders_0.5` means CTR which has combination elements: `workclass`, `race`, `age>24` and is of type `Border` with prior numerator equal `0.5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28f9a65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ctr_feature_id(model_json: dict)-> dict:\n",
    "    model_json = deepcopy(model_json)\n",
    "    cat_features = model_json[\"features_info\"].get(\"categorical_features\", [])\n",
    "    float_features = model_json[\"features_info\"].get(\"float_features\",[])\n",
    "    ctrs = model_json[\"features_info\"].get(\"ctrs\",[])\n",
    "\n",
    "    for ctr in ctrs:\n",
    "        elements = []\n",
    "        for elem in ctr[\"elements\"]:\n",
    "            if elem[\"combination_element\"] == \"cat_feature_value\":\n",
    "                elements.append(cat_features[elem[\"cat_feature_index\"]][\"feature_id\"])\n",
    "            elif elem[\"combination_element\"] == \"float_feature\":\n",
    "                elements.append(f\"{float_features[elem['float_feature_index']]['feature_id']}>{elem[\"border\"]}\")\n",
    "            elif elem[\"combination_element\"] == \"cat_feature_exact_value\":\n",
    "                elements.append(f\"{cat_features[elem[\"cat_feature_index\"]][\"feature_id\"]}=={elem[\"value\"]}\")\n",
    "        feature_id = \"|\".join(elements)\n",
    "        feature_id += f\":{ctr[\"ctr_type\"]}_{ctr[\"prior_numerator\"]}\"\n",
    "        ctr[\"feature_id\"] = feature_id\n",
    "    return model_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23f7cb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "education|hours-per-week>40.5|age>45.5:Borders_0\n"
     ]
    }
   ],
   "source": [
    "model_json_extended = add_ctr_feature_id(model_json=model_json)\n",
    "ctr = model_json_extended[\"features_info\"][\"ctrs\"][200]\n",
    "print(ctr[\"feature_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd39f329",
   "metadata": {},
   "source": [
    "Values needed to calculate CTRs are in:\n",
    "```python\n",
    "model_json[\"ctr_data\"]\n",
    "```\n",
    "which is identifiable by lengthy `identifier` key of ctr `dict`. Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68290534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengthy identifier: {\"identifier\":[{\"cat_feature_index\":1,\"combination_element\":\"cat_feature_value\"},{\"border\":40.5,\"combination_element\":\"float_feature\",\"float_feature_index\":5},{\"border\":45.5,\"combination_element\":\"float_feature\",\"float_feature_index\":0}],\"type\":\"Borders\"} \n",
      "\n",
      "Corresponding 'ctr_data':\n",
      "\n",
      "{'counter_denominator': 0,\n",
      " 'hash_map': ['12149678890856442368',\n",
      "              5682,\n",
      "              633,\n",
      "              '18446744073709551615',\n",
      "              27,\n",
      "              146,\n",
      "              '16943509975464877063',\n",
      "              42,\n",
      "              112,\n",
      "              '4308412934939786119',\n",
      "              507,\n",
      "              329,\n",
      "              '18416576814848222218',\n",
      "              48,\n",
      "              14,\n",
      "              '13748161776802938637',\n",
      "              90,\n",
      "              26,\n",
      "              '16466277097607122449',\n",
      "              33,\n",
      "              1,\n",
      "              '6920013252264861585',\n",
      "              58,\n",
      "              58,\n",
      "              '2246878560390687890',\n",
      "              1170,\n",
      "              1175,\n",
      "              '351594463291488020',\n",
      "              79,\n",
      "              8,\n",
      "              '5487825128174026772',\n",
      "              40,\n",
      "              4,\n",
      "              '4971025666291653780',\n",
      "              359,\n",
      "              9,\n",
      "              '12223166104104329751',\n",
      "              26,\n",
      "              1,\n",
      "              '302610628246370199',\n",
      "              759,\n",
      "              17,\n",
      "              '11921206177417844763',\n",
      "              697,\n",
      "              135,\n",
      "              '715259362051029915',\n",
      "              2264,\n",
      "              611,\n",
      "              '2412854231132517531',\n",
      "              284,\n",
      "              33,\n",
      "              '2417388931293993885',\n",
      "              1453,\n",
      "              560,\n",
      "              '13022867049086889252',\n",
      "              269,\n",
      "              432,\n",
      "              '15356545698592203047',\n",
      "              64,\n",
      "              111,\n",
      "              '12619953465070362924',\n",
      "              90,\n",
      "              13,\n",
      "              '7306171538777690029',\n",
      "              265,\n",
      "              107,\n",
      "              '6733987138044673966',\n",
      "              4,\n",
      "              0,\n",
      "              '13685479780438756913',\n",
      "              85,\n",
      "              7,\n",
      "              '9017064742393473332',\n",
      "              117,\n",
      "              11,\n",
      "              '11127308345279620664',\n",
      "              56,\n",
      "              16,\n",
      "              '11735180063197657144',\n",
      "              40,\n",
      "              0,\n",
      "              '2188916217855396280',\n",
      "              263,\n",
      "              138,\n",
      "              '16128501270432603842',\n",
      "              1206,\n",
      "              22,\n",
      "              '12960152895727239235',\n",
      "              45,\n",
      "              107,\n",
      "              '5624255739029754564',\n",
      "              19,\n",
      "              159,\n",
      "              '2887663505507914441',\n",
      "              19,\n",
      "              7,\n",
      "              '16020625652924793162',\n",
      "              79,\n",
      "              70,\n",
      "              '10625448664182737742',\n",
      "              66,\n",
      "              98,\n",
      "              '16710265554362601678',\n",
      "              664,\n",
      "              630,\n",
      "              '1504468048436388944',\n",
      "              179,\n",
      "              12,\n",
      "              '14814981457263401808',\n",
      "              430,\n",
      "              24,\n",
      "              '7888856430660897619',\n",
      "              434,\n",
      "              17,\n",
      "              '8239809024366691923',\n",
      "              105,\n",
      "              2,\n",
      "              '2575074504368224724',\n",
      "              888,\n",
      "              193,\n",
      "              '2002890103635208661',\n",
      "              5,\n",
      "              0,\n",
      "              '15178646356022943703',\n",
      "              2927,\n",
      "              745,\n",
      "              '16880775925265907673',\n",
      "              1260,\n",
      "              509,\n",
      "              '6396211310870155359',\n",
      "              174,\n",
      "              21,\n",
      "              '9039509969349251424',\n",
      "              279,\n",
      "              338,\n",
      "              '3227862936164790752',\n",
      "              27,\n",
      "              146,\n",
      "              '8229055861317773930',\n",
      "              49,\n",
      "              66,\n",
      "              '6977975594800153195',\n",
      "              278,\n",
      "              559,\n",
      "              '893158704620289259',\n",
      "              68,\n",
      "              249,\n",
      "              '9702122700701119085',\n",
      "              223,\n",
      "              11,\n",
      "              '10218922162583492077',\n",
      "              37,\n",
      "              5,\n",
      "              '5082691497700953325',\n",
      "              108,\n",
      "              22,\n",
      "              '5033707662655835504',\n",
      "              336,\n",
      "              33,\n",
      "              '11289528618515327857',\n",
      "              307,\n",
      "              152,\n",
      "              '16603310544808000752',\n",
      "              66,\n",
      "              11,\n",
      "              '16954263138513795056',\n",
      "              17,\n",
      "              4,\n",
      "              '5446356396460495220',\n",
      "              779,\n",
      "              443,\n",
      "              '16652303211827310068',\n",
      "              170,\n",
      "              82,\n",
      "              '7148485965703459190',\n",
      "              420,\n",
      "              361,\n",
      "              '10083884422853936503',\n",
      "              276,\n",
      "              8,\n",
      "              '15220115087736475255',\n",
      "              226,\n",
      "              6,\n",
      "              '11979168519953136373',\n",
      "              2600,\n",
      "              949,\n",
      "              '3508711989957226618',\n",
      "              91,\n",
      "              1,\n",
      "              '17753964083496354557',\n",
      "              143,\n",
      "              360,\n",
      "              '10447549321613478398',\n",
      "              7311,\n",
      "              704],\n",
      " 'hash_stride': 3}\n"
     ]
    }
   ],
   "source": [
    "identifier = ctr[\"identifier\"]\n",
    "print(\"Lengthy identifier:\", identifier,\"\\n\")\n",
    "print(\"Corresponding 'ctr_data':\\n\")\n",
    "pprint(model_json[\"ctr_data\"][identifier])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d7c3dd",
   "metadata": {},
   "source": [
    "- `counter_denominator` - contains $numberOfInstancesInLargestCategory$ for `Counter` CTRs (is equal to `0` for `Borders` CTRs)\n",
    "- `hash_stride` - contains number of entries in `hash_map` list related to single category\n",
    "- `hash_map` contains\n",
    "  - `[category_1_hash, numberOfFailuresInCategory_1, numberOfSuccessesInCategory_1, category_2_hash, numberOfFailuresInCategory_2, ...]` for `Borders` CTRs\n",
    "  - `[category_1_hash, numberOfInstancesInCategory_1, category_2_hash, numberOfInstancesInCategory_2, ...]` for `Counter` CTRs\n",
    "\n",
    "To calculate CTR values we need also prior numerator and prior denominator which are in `model_json[\"features_info\"][\"ctrs\"]`. These raw CTR values are then scaled and shifted (values of scale and shift are also found in CTR dictionary)\n",
    "$$\n",
    "finalCTR = scale\\times ctr + shift\n",
    "$$\n",
    "Putting everything together we can create dictionary for each CTR which assigns CTR value to category hash. Here is a function that does precisely that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e29ff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ctr_values(model_json: dict) -> dict:\n",
    "    model_json = deepcopy(model_json)\n",
    "    ctrs = model_json[\"features_info\"].get(\"ctrs\", [])\n",
    "    ctr_data = model_json.get(\"ctr_data\", [])\n",
    "\n",
    "    for ctr in ctrs:\n",
    "        identifier = ctr[\"identifier\"]\n",
    "        data = ctr_data[identifier]\n",
    "        stride = data[\"hash_stride\"]\n",
    "        hash_map = data[\"hash_map\"]\n",
    "        prior_denom = ctr[\"prior_denomerator\"] # here is funny typo which haunts CatBoost jsons for many years\n",
    "        prior_num = ctr[\"prior_numerator\"]\n",
    "\n",
    "        ctr_values = {}\n",
    "        if ctr[\"ctr_type\"] == \"Borders\":\n",
    "            for idx in range(0, len(hash_map), stride):\n",
    "                ctr_values[int(hash_map[idx])] = (\n",
    "                    ctr[\"scale\"]\n",
    "                    * (hash_map[idx + 2] + prior_num)\n",
    "                    / (hash_map[idx + 1] + hash_map[idx + 2] + prior_denom)\n",
    "                    + ctr[\"shift\"]\n",
    "                )\n",
    "        elif ctr[\"ctr_type\"] == \"Counter\":\n",
    "            denom = data[\"counter_denominator\"]\n",
    "            for idx in range(0, len(hash_map), stride):\n",
    "                ctr_values[int(hash_map[idx])] = (\n",
    "                    ctr[\"scale\"]\n",
    "                    * (hash_map[idx + 1] + prior_num)\n",
    "                    / (denom + prior_denom)\n",
    "                    + ctr[\"shift\"]\n",
    "                )\n",
    "        ctr[\"ctr_values\"] = ctr_values\n",
    "    return model_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e5d5c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{18446744073709551615: 4.0110998990918265,\n",
       " 15379737126276794113: 5.872295882763433,\n",
       " 1746527532669166693: 0.0,\n",
       " 7024059537692152076: 8.295990566037736,\n",
       " 15472181234288693070: 4.181982914833031,\n",
       " 14256903225472974739: 1.5596080566140447,\n",
       " 18048946643763804916: 4.0110998990918265,\n",
       " 2051959227349154549: 4.432578897035384,\n",
       " 6285290715428032055: 1.1514522821576763,\n",
       " 13863729436386866842: 1.3636363636363635,\n",
       " 8864790892067322495: 3.2679092812693544}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_json_extended = add_ctr_values(model_json_extended)\n",
    "model_json_extended[\"features_info\"][\"ctrs\"][0][\"ctr_values\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bd4e5d",
   "metadata": {},
   "source": [
    "#### Hashing\n",
    "\n",
    "If during json export we also pass training dataset to `pool` parameter, hash values are found in `model_json[\"features_info\"][\"cat_features_hash\"]`. However, this key is not populated if we don't pass trainig dataset. Fortunately, we can recalculate these hashes. CatBoost uses particular implementation of [CityHash64](https://clickhouse.com/docs/native-protocol/hash). Even though this hash has 64 bits, CatBoost uses only 32 least significant bits represented as (signed) `int32`. Here is python version of this hashing function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5d39f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_str(value: str) -> int:\n",
    "    \"\"\"Calculates hash of string (categorical) variables as used in CatBoost.\n",
    "\n",
    "    Uses CityHash64 (`clickhouse_cityhash` implementation).\n",
    "\n",
    "    32 least significant bits are used and represented as (signed) int32.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    value : str\n",
    "        String to be hashed\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        Hash value\n",
    "    \"\"\"\n",
    "    ch = CityHash64(value)\n",
    "    return int((np.uint64(ch) & np.uint64(0xFFFFFFFF)).astype(np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1489e647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hash': 1601642347, 'value': 'Nicaragua'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_hash_examples = model_json_extended[\"features_info\"][\"cat_features_hash\"][0]\n",
    "category_hash_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5392d868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nicaragua has hash=1601642347\n",
      "Is it the same as in model_json? True\n"
     ]
    }
   ],
   "source": [
    "print(f'{category_hash_examples[\"value\"]} has hash={hash_str(category_hash_examples[\"value\"])}')\n",
    "print(f'Is it the same as in model_json? {hash_str(category_hash_examples[\"value\"])==category_hash_examples[\"hash\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3641c7ed",
   "metadata": {},
   "source": [
    "These hashes are used as a numerical representation of a category.\n",
    "\n",
    "Next step is to calculate final hash which is a result of \"mixing\" of all combination elements. If CTR uses only one categorical feature the mixing will be done on a sequence\n",
    "```\n",
    "[0, category_hash]\n",
    "```\n",
    "If there are there are several categorical features as combination elements, the sequence will be\n",
    "```\n",
    "[0, feature_1_category_hash, feature_2_category_hash, ...]\n",
    "```\n",
    "Finally, if one-hot encoded feature or numerical split are among combination elements, binary representation of boolean result of such split is the value used in the sequence. Here example with `1` for first numerical/one-hot split and `0` for the second numerical/one-hot split:\n",
    "```\n",
    "[0, category_hash, 1, 0]\n",
    "```\n",
    "Below are functions that perform this sequential mixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7fe1d5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_hash(\n",
    "    value: int,\n",
    "    starting_hash: int = 0,\n",
    "    max_int: int = 0xFFFFFFFFFFFFFFFF,\n",
    "    magic_mult: int = 0x4906BA494954CB65,\n",
    ") -> int:\n",
    "    \"\"\"Mixes `value` into existing hash (`starting_hash`) to produce new hash.\n",
    "\n",
    "    Default values of `max_int` and `magic_mult` are the same as in CatBoost.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    value : int\n",
    "        Value to be mixed into the `starting_hash`.\n",
    "    starting_hash : int, optional\n",
    "        Hash that the `value` should be mixed into, by default 0\n",
    "    max_int : hexadecimal, optional\n",
    "        Special value for mixing, by default 0xFFFFFFFFFFFFFFFF\n",
    "    magic_mult : hexadecimal, optional\n",
    "        Special value for mixing, by default 0x4906BA494954CB65\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        Mixed hash.\n",
    "    \"\"\"\n",
    "    value = int(value)\n",
    "    starting_hash = int(starting_hash)\n",
    "    return (magic_mult * ((starting_hash + magic_mult * value) & max_int)) & max_int\n",
    "\n",
    "\n",
    "def calc_hash_combination(combination_elements: list)->int:\n",
    "    \"\"\"Given combination elements of CatBoost CTR, calculate hash.\n",
    "\n",
    "    - For categorical features element is their hash value\n",
    "    - For float features element is binary encoding of split condition\n",
    "    - For one-hot feature element is binary encoding of split equality\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    combination_elements : list\n",
    "        List of combination elements\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        Final hash value\n",
    "    \"\"\"    \n",
    "    hash_value = 0\n",
    "    for element in combination_elements:\n",
    "        hash_value = calc_hash(element, starting_hash=hash_value)\n",
    "    return hash_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1ffd27",
   "metadata": {},
   "source": [
    "Let's try to calculate one of the hashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8319e1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTR feature: workclass|age>45.5:Borders_0.5\n",
      "Category value of first element of combination: State-gov . It's hash is: -447941100\n",
      "Final hash after mixing with 1 (example of binary encoding of numerical split) is: 8193958724117795869\n",
      "Is it one of the hashes in model_json for feature 'workclass|age>45.5:Borders_0.5'? True\n"
     ]
    }
   ],
   "source": [
    "ctr = model_json_extended[\"features_info\"][\"ctrs\"][9] # since CatBoost is not deterministic even with set random_state, this particular CTR can contain different features if you run it again\n",
    "print(\"CTR feature:\", ctr[\"feature_id\"])\n",
    "\n",
    "cat_value = X[\"workclass\"].unique()[0] \n",
    "cat_hash = hash_str(cat_value)\n",
    "\n",
    "print(\"Category value of first element of combination:\", cat_value, \". It's hash is:\", cat_hash)\n",
    "\n",
    "final_hash = calc_hash_combination([cat_hash, 1]) # first value is implicitly 0 so we can skip it\n",
    "print(\"Final hash after mixing with 1 (example of binary encoding of numerical split) is:\", final_hash)\n",
    "print(f\"Is it one of the hashes in model_json for feature '{ctr['feature_id']}'?\", final_hash in ctr[\"ctr_values\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ea7461",
   "metadata": {},
   "source": [
    "Now we can wrap everything into functions which will transform dataset by hashing categorical features and extracting CTR features.\n",
    "1. `map_categories_to_hashes` simply applies hashing function to category values\n",
    "2. `create_ctr_features`\n",
    "    - for each CTR feature collects combination elements (category hashes, binary encodings of numerical splits or one-hot splits)\n",
    "    - calculates sequantial hash mixing of these elements\n",
    "    - maps final hash values to respective CTR values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7272565e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_categories_to_hashes(X: pd.DataFrame) -> pd.DataFrame:\n",
    "    X = X.copy(deep=True)\n",
    "    cat_features = X.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "    X[cat_features] = X[cat_features].map(hash_str)\n",
    "    return X\n",
    "\n",
    "def create_ctr_features(X_cb: pd.DataFrame, model_json: dict) -> pd.DataFrame:\n",
    "    X_cb = X_cb.copy(deep=True)\n",
    "    ctrs = model_json[\"features_info\"].get(\"ctrs\", [])\n",
    "    cat_features = model_json[\"features_info\"].get(\"categorical_features\",[])\n",
    "    float_features = model_json[\"features_info\"].get(\"float_features\",[])\n",
    "\n",
    "    ctr_features_list = []\n",
    "    for ctr in tqdm(ctrs):\n",
    "        feature_id = ctr[\"feature_id\"]\n",
    "        combination_elements_list =[]\n",
    "        for elem in ctr[\"elements\"]:\n",
    "            if elem[\"combination_element\"] == \"cat_feature_value\":\n",
    "                feature_element_id = cat_features[elem[\"cat_feature_index\"]][\n",
    "                    \"feature_id\"\n",
    "                ]\n",
    "                value = X_cb[feature_element_id] # here category hash value\n",
    "            elif elem[\"combination_element\"] == \"float_feature\":\n",
    "                feature_element_id = float_features[elem[\"float_feature_index\"]][\n",
    "                    \"feature_id\"\n",
    "                ]\n",
    "                value = (X_cb[feature_element_id] > elem[\"border\"]).astype(int) # binary encoding of numerical split\n",
    "            elif elem[\"combination_element\"] == \"cat_feature_exact_value\":\n",
    "                feature_element_id = cat_features[elem[\"cat_feature_index\"]][\n",
    "                    \"feature_id\"\n",
    "                ]\n",
    "                value = (X_cb[feature_element_id] == elem[\"value\"]).astype(int) # binary encoding of one-hot split\n",
    "\n",
    "            combination_elements_list.append(value) # collect all combination elements\n",
    "\n",
    "        combination_elements_df = pd.concat(combination_elements_list, axis=1)            \n",
    "        series_temp = combination_elements_df.apply(calc_hash_combination, axis=1) \n",
    "        series_temp = series_temp.map(ctr[\"ctr_values\"]) # map hashes to ctr values\n",
    "        series_temp.name = feature_id\n",
    "        ctr_features_list.append(series_temp)\n",
    "\n",
    "    X_cb = pd.concat([X_cb, *ctr_features_list], axis=1)\n",
    "    return X_cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b74c097b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 610/610 [01:07<00:00,  8.99it/s]\n"
     ]
    }
   ],
   "source": [
    "X_cb = map_categories_to_hashes(X_cb)\n",
    "X_cb = create_ctr_features(X_cb, model_json=model_json_extended)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ca594c",
   "metadata": {},
   "source": [
    "Dataset is expanded by CTR features and consists of only numerical features - conceptually CatBoost does the same thing internally (but faster and more efficient).\n",
    "\n",
    "In \"Census Income\" there quite a few categorical features. As a result CatBoost created many CTRs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8c4c21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Columns: 624 entries, age to native-country|hours-per-week>73.5:Borders_1\n",
      "dtypes: float64(612), int64(12)\n",
      "memory usage: 232.5 MB\n"
     ]
    }
   ],
   "source": [
    "X_cb.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446ce8bd",
   "metadata": {},
   "source": [
    "### Trees\n",
    "\n",
    "CatBoost uses oblivious trees - at each level the same split is performed in all nodes at this level. This means that decision path can be encoded as binary vector. This binary vector can be turned into integer index in the list of all leaf values. Leaf values are possible prediction of that tree. So if for a given tree path an instance took is e.g. `[Greater, Not greater, Greater]` (tree of `depth=3`) it is encoded as `101`. Therefore corresponding leaf value is at index `0b101=5`. \n",
    "\n",
    "Let's look at example of CatBoost tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae406e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'leaf_values': [-0.053246387294678704,\n",
      "                 0.04344816195199846,\n",
      "                 -0.03889367593239945,\n",
      "                 0.011376445792702607,\n",
      "                 0,\n",
      "                 0,\n",
      "                 0,\n",
      "                 0,\n",
      "                 -0.049786560982482714,\n",
      "                 -0.07900743970240365,\n",
      "                 -0.014231091855371053,\n",
      "                 -0.03105123577189302,\n",
      "                 0,\n",
      "                 0,\n",
      "                 0,\n",
      "                 0,\n",
      "                 -0.02992219933327188,\n",
      "                 -0.008388896899044455,\n",
      "                 -0.00948424520345465,\n",
      "                 -0.015603536432856592,\n",
      "                 0,\n",
      "                 0,\n",
      "                 0,\n",
      "                 0,\n",
      "                 -0.028782229264519957,\n",
      "                 -0.04281970650040307,\n",
      "                 0.038200608259269714,\n",
      "                 -0.013399462043038334,\n",
      "                 0,\n",
      "                 0,\n",
      "                 0,\n",
      "                 0,\n",
      "                 -0.02922295387235034,\n",
      "                 -0.0223052822306792,\n",
      "                 0,\n",
      "                 -0.005027282326097987,\n",
      "                 0,\n",
      "                 0,\n",
      "                 0,\n",
      "                 0,\n",
      "                 -0.028517856734116966,\n",
      "                 -0.05213781076764734,\n",
      "                 0.01997300352910049,\n",
      "                 -0.020967576377446444,\n",
      "                 0.14464977191876593,\n",
      "                 0,\n",
      "                 0,\n",
      "                 0.13241087755859765,\n",
      "                 -0.034443054683459436,\n",
      "                 -0.009700056876216646,\n",
      "                 -0.06048497526743249,\n",
      "                 -0.020454962375279447,\n",
      "                 -0.015540529025643242,\n",
      "                 0,\n",
      "                 0,\n",
      "                 0.11367182530284883,\n",
      "                 -0.000260352511283888,\n",
      "                 -0.011475485071465653,\n",
      "                 0.019509111890623404,\n",
      "                 0.013317737202802257,\n",
      "                 0.06523007063387751,\n",
      "                 0.13341628676100314,\n",
      "                 0.07621787400241355,\n",
      "                 0.10730703060823238],\n",
      " 'leaf_weights': [2146,\n",
      "                  14,\n",
      "                  9,\n",
      "                  53,\n",
      "                  0,\n",
      "                  0,\n",
      "                  0,\n",
      "                  0,\n",
      "                  7689,\n",
      "                  202,\n",
      "                  65,\n",
      "                  1299,\n",
      "                  0,\n",
      "                  0,\n",
      "                  0,\n",
      "                  0,\n",
      "                  2032,\n",
      "                  19,\n",
      "                  8,\n",
      "                  64,\n",
      "                  0,\n",
      "                  0,\n",
      "                  0,\n",
      "                  0,\n",
      "                  4300,\n",
      "                  261,\n",
      "                  54,\n",
      "                  1079,\n",
      "                  0,\n",
      "                  0,\n",
      "                  0,\n",
      "                  0,\n",
      "                  29,\n",
      "                  3,\n",
      "                  0,\n",
      "                  1,\n",
      "                  0,\n",
      "                  0,\n",
      "                  0,\n",
      "                  0,\n",
      "                  1389,\n",
      "                  45,\n",
      "                  20,\n",
      "                  322,\n",
      "                  4,\n",
      "                  0,\n",
      "                  0,\n",
      "                  2,\n",
      "                  1883,\n",
      "                  33,\n",
      "                  18,\n",
      "                  83,\n",
      "                  10,\n",
      "                  0,\n",
      "                  0,\n",
      "                  3,\n",
      "                  16175,\n",
      "                  1391,\n",
      "                  558,\n",
      "                  7423,\n",
      "                  58,\n",
      "                  8,\n",
      "                  3,\n",
      "                  87],\n",
      " 'splits': [{'border': 4.999999046325684,\n",
      "             'ctr_target_border_idx': 0,\n",
      "             'split_index': 1314,\n",
      "             'split_type': 'OnlineCtr'},\n",
      "            {'border': 5.999999046325684,\n",
      "             'ctr_target_border_idx': 0,\n",
      "             'split_index': 640,\n",
      "             'split_type': 'OnlineCtr'},\n",
      "            {'border': 2384.5,\n",
      "             'float_feature_index': 4,\n",
      "             'split_index': 333,\n",
      "             'split_type': 'FloatFeature'},\n",
      "            {'border': 8.5,\n",
      "             'float_feature_index': 2,\n",
      "             'split_index': 226,\n",
      "             'split_type': 'FloatFeature'},\n",
      "            {'border': 28.5,\n",
      "             'float_feature_index': 0,\n",
      "             'split_index': 6,\n",
      "             'split_type': 'FloatFeature'},\n",
      "            {'border': 1.9999990463256836,\n",
      "             'ctr_target_border_idx': 0,\n",
      "             'split_index': 1599,\n",
      "             'split_type': 'OnlineCtr'}]}\n"
     ]
    }
   ],
   "source": [
    "pprint(model_json[\"oblivious_trees\"][42])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f216cc0d",
   "metadata": {},
   "source": [
    "Each tree contains:\n",
    "- `leaf_values` - list of all leaf values; number of leaves is $2^{depth}$ (if there are more classes, this is multiplied by $n_{classes}$)\n",
    "- `leaf_weights` - number of instances that landed in this leaf (if instances were weighted this is taken into account here)\n",
    "- `splits` list of all splits in this tree\n",
    "\n",
    "#### Splits\n",
    "Split have their own structure:\n",
    "- `split_type` - one of `FloatFeature` (numerical split), `OnlineCtr` (CTR feature split), `OneHotFeature` (categorical one-hot split)\n",
    "- `split_index` - index in the list of all borders in the whole model which are concatenated in the following order (they are not explicitly saved in `model_json`)\n",
    "    - `float_features` - all borders for each feature\n",
    "    - `categorical_features` - only values of one-hot encoded features used as split conditions\n",
    "    - `ctrs` - all borders for each CTR\n",
    "- `border` (for numerical splits or CTRs) or `value` (for one-hot splits) - value used in this split condition\n",
    "- `float_feature_index` or `cat_feature_index` - index among given type of features\n",
    "- `ctr_target_border_idx` - always `0` for binary classification\n",
    "\n",
    "For numerical splits, we can quickly determine which feature must be used for this split. However, for CTRs we need to look for correct one using `split_index`. To make our life easier we can add list of all splits, which will contain feature names (for extracted CTR features as well). Here is a function that does that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23a9535f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_all_splits(model_json: dict)-> dict:\n",
    "    model_json = deepcopy(model_json)\n",
    "    cat_features = model_json[\"features_info\"].get(\"categorical_features\", [])\n",
    "    float_features = model_json[\"features_info\"].get(\"float_features\",[])\n",
    "    ctrs = model_json[\"features_info\"].get(\"ctrs\",[])\n",
    "\n",
    "    model_json[\"all_splits\"] = []\n",
    "    for idx, feature_dict in enumerate(float_features):\n",
    "        for border in feature_dict[\"borders\"]:\n",
    "            split_dict = {\n",
    "                \"feature_id\": feature_dict[\"feature_id\"],\n",
    "                \"border\": border,\n",
    "                \"split_type\": \"FloatFeature\",\n",
    "                \"feature_idx_in_type\": idx,\n",
    "            }\n",
    "            model_json[\"all_splits\"].append(split_dict)\n",
    "\n",
    "    for idx, feature_dict in enumerate(cat_features):\n",
    "        if \"values\" in feature_dict.keys():\n",
    "            for value in feature_dict[\"values\"]:\n",
    "                split_dict = {\n",
    "                    \"feature_id\": feature_dict[\"feature_id\"],\n",
    "                    \"border\": value,\n",
    "                    \"split_type\": \"OneHotFeature\",\n",
    "                    \"feature_idx_in_type\": idx,\n",
    "                }\n",
    "                model_json[\"all_splits\"].append(split_dict)\n",
    "\n",
    "    for idx, feature_dict in enumerate(ctrs):\n",
    "        for border in feature_dict[\"borders\"]:\n",
    "            split_dict = {\n",
    "                \"feature_id\": feature_dict[\"feature_id\"],\n",
    "                \"border\": border,\n",
    "                \"split_type\": \"OnlineCtr\",\n",
    "                \"feature_idx_in_type\": idx,\n",
    "            }\n",
    "            model_json[\"all_splits\"].append(split_dict)\n",
    "    return model_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "16c60ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1818 unique splits in the model.\n"
     ]
    }
   ],
   "source": [
    "model_json_extended = add_all_splits(model_json_extended)\n",
    "print(f\"There are {len(model_json_extended[\"all_splits\"])} unique splits in the model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfad611f",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "\n",
    "Now that all splits are turned into numerical, and we know how to turn them into binary decision vector, we can recalculate prediction.\n",
    "\n",
    "Tree ensemble models simply sum up leaf values of all the trees, possibly scale them and add bias. For classifier model's raw prediction output is in log-odds space (because log-odds space is additive). To get more intuitive probability output raw prediction needs to be passed through `expit` function.\n",
    "\n",
    "Here is a function that recalculates prediction based on expanded `model_json` structure and extracted CTR features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca028f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_cb: pd.DataFrame, model_json: dict) -> pd.Series:\n",
    "    prediction = np.zeros_like(X_cb.index, dtype=np.float64)\n",
    "    scale, bias = model_json[\"scale_and_bias\"]\n",
    "    trees = model_json[\"oblivious_trees\"]\n",
    "    all_splits = model_json[\"all_splits\"]\n",
    "\n",
    "    for tree in trees:\n",
    "        splits = tree.get(\"splits\",[])\n",
    "        splits = splits if splits is not None else [] \n",
    "        leaf_idx = np.zeros_like(prediction, dtype=np.int32)\n",
    "        for idx, split in enumerate(splits):\n",
    "            split = all_splits[split[\"split_index\"]]\n",
    "            if split[\"split_type\"] == \"OneHotFeature\":\n",
    "                bin_value = X_cb[split[\"feature_id\"]] == split[\"border\"]\n",
    "            else:\n",
    "                bin_value = X_cb[split[\"feature_id\"]] > split[\"border\"]\n",
    "            \n",
    "            leaf_idx += (2**idx)*bin_value\n",
    "        leaf_values = np.array(tree[\"leaf_values\"])\n",
    "        prediction += leaf_values[leaf_idx]\n",
    "\n",
    "    return scale*prediction + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1b68bddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_recalc = expit(predict(X_cb, model_json_extended))\n",
    "pred_original = model.predict_proba(X)[:,1]\n",
    "np.max(np.abs(pred_original - pred_recalc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0782cf5b",
   "metadata": {},
   "source": [
    "The prediction matches exactly!\n",
    "\n",
    "### Some fun with the model\n",
    "\n",
    "We can use only some of the trees by simply removing them from json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0847b7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trees in original model is 1000\n",
      "Number of trees in small model is 500\n"
     ]
    }
   ],
   "source": [
    "model_small_json = deepcopy(model_json)\n",
    "model_small_json[\"oblivious_trees\"][:250] = []\n",
    "model_small_json[\"oblivious_trees\"][-250:] = []\n",
    "\n",
    "# do the same to extended version\n",
    "model_small_json_extended = deepcopy(model_json_extended)\n",
    "model_small_json_extended[\"oblivious_trees\"][:250] = []\n",
    "model_small_json_extended[\"oblivious_trees\"][-250:] = []\n",
    "print(f\"Number of trees in original model is {len(model_json['oblivious_trees'])}\")\n",
    "print(f\"Number of trees in small model is {len(model_small_json['oblivious_trees'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e939afc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7b744587ce10>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"catboost_model_small.json\", mode=\"w+\") as f:\n",
    "    json.dump(model_small_json, f, indent=2)\n",
    "model_small = CatBoostClassifier()\n",
    "model_small.load_model(\"catboost_model_small.json\", format=\"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "95557ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2.220446049250313e-16)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_recalc = expit(predict(X_cb, model_small_json_extended))\n",
    "pred_original = model_small.predict_proba(X)[:,1]\n",
    "np.max(np.abs(pred_original - pred_recalc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d5073d",
   "metadata": {},
   "source": [
    "Here we have small numerical error but it is exactly the same as if we were to use CatBoost build-in solution to choose trees for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9c2da7af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2.220446049250313e-16)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.abs(model.predict_proba(X, ntree_start=250, ntree_end=750)[:,1] - pred_original))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5d06b0",
   "metadata": {},
   "source": [
    "We can also flip the model so it predicts who earns *less than* instead of *more than* 50k. Do do that, we need to multiply each leaf value by `-1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "85ecb7d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2.220446049250313e-16)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_flipped_json_extended = deepcopy(model_json_extended)\n",
    "for tree in model_flipped_json_extended[\"oblivious_trees\"]:\n",
    "    for i in range(len(tree[\"leaf_values\"])):\n",
    "        tree[\"leaf_values\"][i] *= -1\n",
    "\n",
    "pred_recalc = expit(predict(X_cb, model_flipped_json_extended))\n",
    "pred_original = model.predict_proba(X)[:,1]\n",
    "np.max(np.abs(1-(pred_original + pred_recalc))) # original predictions + flipped prediction must add-up to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9a8ed5",
   "metadata": {},
   "source": [
    "Again, only small numerical errors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
