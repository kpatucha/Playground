{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of Kullback-Leibler divergence estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import functools\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import KDTree\n",
    "from typing import Literal\n",
    "from sklearn.preprocessing import KBinsDiscretizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empirical CDF estimator\n",
    "\n",
    "Proposed by [Fernando PÃ©rez-Cruz](https://ieeexplore.ieee.org/document/4595271)\n",
    "\n",
    "Implementation based on post by [kjetil b halvorsen](https://stats.stackexchange.com/questions/211175/kullback-leibler-divergence-for-two-samples/248657#248657)\n",
    "with Run Length Encoding code by [Thomas Browne](https://stackoverflow.com/a/32681075)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle(inarray):\n",
    "    \"\"\"Run Length Encoding. Doesn't perform sort internally.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    inarray : 1d array-like\n",
    "        Array to be encoded.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    z : np.ndarray\n",
    "        Run lengths\n",
    "    p : np.ndarray\n",
    "        Positions\n",
    "    v : np.ndarray\n",
    "        Values\n",
    "    \"\"\"\n",
    "    ia = np.asarray(inarray)  # force numpy\n",
    "    n = len(ia)\n",
    "    if n == 0:\n",
    "        return (None, None, None)\n",
    "    else:\n",
    "        y = ia[1:] != ia[:-1]  # pairwise unequal (string safe)\n",
    "        i = np.append(np.where(y), n - 1)  # must include last element posi\n",
    "        z = np.diff(np.append(-1, i))  # run lengths\n",
    "        p = np.cumsum(np.append(0, z))[:-1]  # positions\n",
    "        return (z, p, ia[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecdf(X, X_min=None, X_max=None):\n",
    "    \"\"\"Empirical CDF (cumulative distribution funciton) from random sample.\n",
    "\n",
    "    Continous approximation via linear interpolation.\n",
    "    \n",
    "    Returns function which can be used to get value of empirical CDF for any point.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 1d array-like\n",
    "        Random sample\n",
    "    X_min : float, default=None\n",
    "        Left limit of the domain\n",
    "    X_max : 1d array-like, default=None\n",
    "        Right limit of the domain\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cdf : function\n",
    "        Empirical CDF\n",
    "    \"\"\"\n",
    "    X = np.asarray(X, copy=True)\n",
    "    n = len(X)\n",
    "    X.sort()\n",
    "\n",
    "    X_u = np.unique(X)\n",
    "    # In case there are duplicates perform rle\n",
    "    if n != len(X_u):\n",
    "        X_rle, _, _ = rle(X)\n",
    "    else:\n",
    "        X_rle = np.ones_like(X)\n",
    "\n",
    "    # Points going through middle of step function centered at points from the sample (in case duplicates stacked steps)\n",
    "    y = (np.cumsum(X_rle) - 0.5 * X_rle) / n\n",
    "    # Attach left and right limit for proper interpolation\n",
    "    if (X_min is not None) and (X_u[0] != X_min):\n",
    "        X_u = np.concatenate([[X_min], X_u])\n",
    "        y = np.concatenate([[0], y])\n",
    "    if (X_max is not None) and (X_u[-1] != X_max):\n",
    "        X_u = np.concatenate([X_u, [X_max]])\n",
    "        y = np.concatenate([y, [1]])\n",
    "        \n",
    "    return functools.partial(np.interp, xp=X_u, fp=y, left=0, right=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_div(X, Y, eps=None, num_instab: Literal[\"warning\", \"ignore\"] = \"warning\"):\n",
    "    \"\"\"Kullback-Leibler divergence (relative entropy) estimator.\n",
    "\n",
    "    According to Perez-Cruz algorithm using empirical CDFs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 1d array-like\n",
    "        Random sample (\"true\" distribution).\n",
    "    Y : 1d array-like\n",
    "        Random sample (\"model\" distribution).\n",
    "    eps : float, default=None\n",
    "        epsilon for calculation of CDFs differential.\n",
    "    num_instab : {'warning', 'ignore'}, default='warning'\n",
    "        How to handle numerical instability caused by close to horizontal CDF of Y.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    kl_div : float\n",
    "        Estimation of Kullback-Leibler divergence.\n",
    "    \"\"\"\n",
    "    # Force numpy array\n",
    "    X = np.asarray(X, copy=True)\n",
    "    Y = np.asarray(Y, copy=True)\n",
    "\n",
    "    if eps is None:\n",
    "        # Calculate epsilon two times smaller than smallest spacing between points in each random sample\n",
    "        X_u = np.unique(X)\n",
    "        X_u.sort()\n",
    "        Y_u = np.unique(Y)\n",
    "        Y_u.sort()\n",
    "        dx = np.diff(X_u)\n",
    "        dy = np.diff(Y_u)\n",
    "        eps = np.concat([dx, dy]).min() / 2\n",
    "\n",
    "    tot_domain = np.concat([X, Y])\n",
    "    tot_min = tot_domain.min() - eps\n",
    "    tot_max = tot_domain.max()\n",
    "\n",
    "    # \"Stretch\" Q CDF to avoid division by zero\n",
    "    P = ecdf(X)\n",
    "    Q = ecdf(Y, X_min=tot_min, X_max=tot_max)\n",
    "\n",
    "    dP = P(X) - P(X - eps)\n",
    "    dQ = Q(X) - Q(X - eps)\n",
    "\n",
    "    mask_dP = dP != 0.0\n",
    "    mask_dQ = dQ != 0.0\n",
    "    mask = mask_dP & mask_dQ\n",
    "\n",
    "    # Raise warning\n",
    "    if num_instab == \"warning\":\n",
    "        if (problems := (~mask_dQ).sum()) != 0:\n",
    "            print(\n",
    "                f\"{problems} point removed due to zeros encounter in dQ. This suggests numerical instability - return value might not be reliable. Try dividing sample in few parts and taking average result.\"\n",
    "            )\n",
    "\n",
    "    # Non-singular elemnts\n",
    "    odds = dP[mask] / dQ[mask]\n",
    "    # Include zeros of dP - since they contribute 0, we need to only modify normalization n\n",
    "    n = len(odds) + (~mask_dP).sum()\n",
    "    result = np.log(odds).sum() / n - 1\n",
    "\n",
    "    # Force non-negative result\n",
    "    return max(result, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## knn estimator\n",
    "\n",
    "Proposed by [Wang et al.](https://ieeexplore.ieee.org/document/4839047)\n",
    "\n",
    "Code by [Nathan Hartland](https://github.com/nhartland/KL-divergence-estimators/tree/master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_sample_shapes(s1, s2, k):\n",
    "    # Expects [N, D]\n",
    "    assert len(s1.shape) == len(s2.shape) == 2\n",
    "    # Check dimensionality of sample is identical\n",
    "    assert s1.shape[1] == s2.shape[1]\n",
    "    \n",
    "def scipy_estimator(s1, s2, k=1):\n",
    "    \"\"\"KL-Divergence estimator using scipy's KDTree\n",
    "    s1: (N_1,D) Sample drawn from distribution P\n",
    "    s2: (N_2,D) Sample drawn from distribution Q\n",
    "    k: Number of neighbours considered (default 1)\n",
    "    return: estimated D(P|Q)\n",
    "    \"\"\"\n",
    "    verify_sample_shapes(s1, s2, k)\n",
    "\n",
    "    n, m = len(s1), len(s2)\n",
    "    d = float(s1.shape[1])\n",
    "    D = np.log(m / (n - 1))\n",
    "\n",
    "    nu_d, _ = KDTree(s2).query(s1, k)\n",
    "    rho_d, _ = KDTree(s1).query(s1, k + 1)\n",
    "\n",
    "    # KTree.query returns different shape in k==1 vs k > 1\n",
    "    if k > 1:\n",
    "        D += (d / n) * np.sum(np.log(nu_d[::, -1] / rho_d[::, -1]))\n",
    "    else:\n",
    "        D += (d / n) * np.sum(np.log(nu_d / rho_d[::, -1]))\n",
    "\n",
    "    return max(D, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binning estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_div_bin(X, Y, n_bins=10, strategy=\"quantile\", verbose=False):\n",
    "    n_x = len(X)\n",
    "    n_y = len(Y)\n",
    "    binner = KBinsDiscretizer(n_bins=n_bins, encode=\"ordinal\", strategy=strategy)\n",
    "    X_binned = binner.fit_transform(X)\n",
    "    Y_binned = binner.transform(Y)\n",
    "\n",
    "    result = 0\n",
    "    for i in range(n_bins):\n",
    "        y_count = (Y_binned == i).sum()\n",
    "\n",
    "        if y_count == 0:\n",
    "            if verbose:\n",
    "                print(\"Empty bin for Y - value omitted\")\n",
    "            continue\n",
    "\n",
    "        x_count = (X_binned == i).sum()\n",
    "        \n",
    "        result += x_count/n_x * np.log((x_count/n_x)/(y_count/n_y))\n",
    "    return max(0,result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analytic KL divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_div_norm_norm(mu_1, sigma_1, mu_2, sigma_2):\n",
    "    return ((mu_1 - mu_2) ** 2 + sigma_1**2 - sigma_2**2) / (\n",
    "        2 * sigma_2**2\n",
    "    ) + np.log(sigma_2 / sigma_1)\n",
    "\n",
    "\n",
    "def kl_div_uni_uni(a_1, b_1, a_2, b_2):\n",
    "    return np.log((b_2 - a_2) / (b_1 - a_1))\n",
    "\n",
    "\n",
    "def kl_div_exp_exp(lambda_1, lambda_2):\n",
    "    return np.log(lambda_1 / lambda_2) + lambda_2 / lambda_1 - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-divergence standard normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical CDF estimator - 0.0004567471939944667\n",
      "knn estimator           - 0\n",
      "Binning estimator       - 0.00011878705189443382\n",
      "Analytical result       - 0.0\n"
     ]
    }
   ],
   "source": [
    "mu_1 = 0\n",
    "sigma_1 = 1\n",
    "mu_2 = mu_1\n",
    "sigma_2 = sigma_1\n",
    "rng = np.random.default_rng(seed=42)\n",
    "X = rng.normal(mu_1, sigma_1, 100_000)\n",
    "Y = rng.normal(mu_2, sigma_2, 100_000)\n",
    "print(f\"Empirical CDF estimator - {kl_div(X, Y)}\")\n",
    "print(f\"knn estimator           - {scipy_estimator(X.reshape(-1,1), Y.reshape(-1,1))}\")\n",
    "print(f\"Binning estimator       - {kl_div_bin(X.reshape(-1,1), Y.reshape(-1,1))}\")\n",
    "print(f\"Analytical result       - {kl_div_norm_norm(mu_1, sigma_1, mu_2, sigma_2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two normal distributions - $\\mathcal{N}(0,1)$ and $\\mathcal{N}(0,2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical CDF estimator - 0.3148033341857741\n",
      "knn estimator           - 0.31550281847300415\n",
      "Binning estimator       - 0.23010721551018237\n",
      "Analytical result       - 0.3181471805599453\n"
     ]
    }
   ],
   "source": [
    "mu_1 = 0\n",
    "sigma_1 = 1\n",
    "mu_2 = 0\n",
    "sigma_2 = 2\n",
    "size = 100_000\n",
    "rng = np.random.default_rng(seed=42)\n",
    "X = rng.normal(mu_1, sigma_1, size)\n",
    "Y = rng.normal(mu_2, sigma_2, size)\n",
    "print(f\"Empirical CDF estimator - {kl_div(X, Y)}\")\n",
    "print(f\"knn estimator           - {scipy_estimator(X.reshape(-1,1), Y.reshape(-1,1))}\")\n",
    "print(f\"Binning estimator       - {kl_div_bin(X.reshape(-1,1), Y.reshape(-1,1))}\")\n",
    "print(f\"Analytical result       - {kl_div_norm_norm(mu_1, sigma_1, mu_2, sigma_2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two normal distributions - $P\\sim\\mathcal{N}(0,1)$ and $Q\\sim\\mathcal{N}(0,0.2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6898 point removed due to zeros encounter in dQ. This suggests numerical instability - return value might not be reliable. Try dividing sample in few parts and taking average result.\n",
      "Empirical CDF estimator - 4.146234064438398\n",
      "knn estimator           - 4.207346717859741\n",
      "Binning estimator       - 1.97754059004881\n",
      "Analytical result       - 10.390562087565897\n"
     ]
    }
   ],
   "source": [
    "mu_1 = 0\n",
    "sigma_1 = 1\n",
    "mu_2 = 0\n",
    "sigma_2 = 0.2\n",
    "size = 100_000\n",
    "rng = np.random.default_rng(seed=42)\n",
    "X = rng.normal(mu_1, sigma_1, size)\n",
    "Y = rng.normal(mu_2, sigma_2, size)\n",
    "print(f\"Empirical CDF estimator - {kl_div(X, Y)}\")\n",
    "print(f\"knn estimator           - {scipy_estimator(X.reshape(-1,1), Y.reshape(-1,1))}\")\n",
    "print(f\"Binning estimator       - {kl_div_bin(X.reshape(-1,1), Y.reshape(-1,1))}\")\n",
    "print(f\"Analytical result       - {kl_div_norm_norm(mu_1, sigma_1, mu_2, sigma_2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warning is caused by flat regions of empirical CDF of $Q$ which have to be removed.\n",
    " \n",
    "In this case all methods differ from analytical result. This is caused by regions where distributions differ significantly - even by orders of magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(X, bins=100, density=True, alpha=0.6)\n",
    "plt.hist(Y, bins=100, density=True, alpha=0.6)\n",
    "# plt.hist(np.append(X,Y), bins=100, density=True, alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999\n",
      "Empirical CDF estimator          - 3.951123498073733 +/- 0.4454386667139436\n",
      "Empirical CDF estimator averaged - 4.146422084060579 +/- 0.03987596716105402\n",
      "knn estimator                    - 4.396171911959766 +/- 0.07136277428268406\n",
      "Binning estimator                - 1.6355941062122235 +/- 0.5385350060505641\n",
      "Analytical result                - 10.390562087565897\n"
     ]
    }
   ],
   "source": [
    "mu_1 = 0\n",
    "sigma_1 = 1\n",
    "mu_2 = 0\n",
    "sigma_2 = 0.2\n",
    "size = 100_000\n",
    "rng = np.random.default_rng(seed=42)\n",
    "ecdf_kl_list = []\n",
    "ecdf_kl_avg_list = []\n",
    "knn_kl_list = []\n",
    "bin_kl_list = []\n",
    "\n",
    "n = 1000\n",
    "n_chunks = 10\n",
    "for i in range(n):\n",
    "    X = rng.normal(mu_1, sigma_1, size)\n",
    "    Y = rng.normal(mu_2, sigma_2, size)\n",
    "\n",
    "    ecdf_kl_list.append(kl_div(X, Y, num_instab=\"ignore\"))\n",
    "    kl_div_loop = []\n",
    "    for j in range(n_chunks):\n",
    "        chunk_start = j*size//n_chunks\n",
    "        chunk_end = (j+1)*size//n_chunks\n",
    "        kl_div_loop.append(kl_div(X[chunk_start:chunk_end],Y[chunk_start:chunk_end], num_instab=\"ignore\"))\n",
    "\n",
    "    ecdf_kl_avg_list.append(np.mean(kl_div_loop))    \n",
    "\n",
    "    knn_kl_list.append(scipy_estimator(X.reshape(-1,1), Y.reshape(-1,1)))\n",
    "    bin_kl_list.append(kl_div_bin(X.reshape(-1,1), Y.reshape(-1,1)))\n",
    "    print(i, flush=True, end=\"\\r\")\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(f\"Empirical CDF estimator          - {np.mean(ecdf_kl_list)} +/- {np.std(ecdf_kl_list)}\")\n",
    "print(f\"Empirical CDF estimator averaged - {np.mean(ecdf_kl_avg_list)} +/- {np.std(ecdf_kl_avg_list)}\")\n",
    "print(f\"knn estimator                    - {np.mean(knn_kl_list)} +/- {np.std(knn_kl_list)}\")\n",
    "print(f\"Binning estimator                - {np.mean(bin_kl_list)} +/- {np.std(bin_kl_list)}\")\n",
    "print(f\"Analytical result                - {kl_div_norm_norm(mu_1, sigma_1, mu_2, sigma_2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
